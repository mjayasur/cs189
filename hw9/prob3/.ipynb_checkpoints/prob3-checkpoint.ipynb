{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.spatial\n",
    "from starter import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "## Models used for predictions.\n",
    "#####################################################################\n",
    "def compute_update(single_obj_loc, sensor_loc, single_distance):\n",
    "    \"\"\"\n",
    "    Compute the gradient of the loglikelihood function for part a.\n",
    "\n",
    "    Input:\n",
    "    single_obj_loc: 1 * d numpy array.\n",
    "    Location of the single object.\n",
    "\n",
    "    sensor_loc: k * d numpy array.\n",
    "    Location of sensor.\n",
    "\n",
    "    single_distance: k dimensional numpy array.\n",
    "    Observed distance of the object.\n",
    "\n",
    "    Output:\n",
    "    grad: d-dimensional numpy array.\n",
    "\n",
    "    \"\"\"\n",
    "    loc_difference = single_obj_loc - sensor_loc  # k * d.\n",
    "    phi = np.linalg.norm(loc_difference, axis=1)  # k.\n",
    "    grad = loc_difference / np.expand_dims(phi, 1)  # k * 2.\n",
    "    update = np.linalg.solve(\n",
    "        grad.T.dot(grad), grad.T.dot(single_distance - phi))\n",
    "\n",
    "    return update\n",
    "\n",
    "\n",
    "def get_object_location(sensor_loc,\n",
    "                        single_distance,\n",
    "                        num_iters=20,\n",
    "                        num_repeats=10):\n",
    "    \"\"\"\n",
    "    Compute the gradient of the loglikelihood function for part a.\n",
    "\n",
    "    Input:\n",
    "\n",
    "    sensor_loc: k * d numpy array. Location of sensor.\n",
    "\n",
    "    single_distance: k dimensional numpy array.\n",
    "    Observed distance of the object.\n",
    "\n",
    "    Output:\n",
    "    obj_loc: 1 * d numpy array. The mle for the location of the object.\n",
    "\n",
    "    \"\"\"\n",
    "    obj_locs = np.zeros((num_repeats, 1, 2))\n",
    "    distances = np.zeros(num_repeats)\n",
    "    for i in range(num_repeats):\n",
    "        obj_loc = np.random.randn(1, 2) * 100\n",
    "        for t in range(num_iters):\n",
    "            obj_loc += compute_update(obj_loc, sensor_loc, single_distance)\n",
    "\n",
    "        distances[i] = np.sum(\n",
    "            (single_distance - np.linalg.norm(obj_loc - sensor_loc, axis=1))\n",
    "            **2)\n",
    "        obj_locs[i] = obj_loc\n",
    "\n",
    "    obj_loc = obj_locs[np.argmin(distances)]\n",
    "\n",
    "    return obj_loc[0]\n",
    "\n",
    "\n",
    "def generative_model(X, Y, Xs_test, Ys_test):\n",
    "    \"\"\"\n",
    "    This function implements the generative model.\n",
    "    Input:\n",
    "    X: independent variables in training data.\n",
    "    Y: dependent variables in training data.\n",
    "    Xs_test: independent variables in test data.\n",
    "    Ys_test: dependent variables in test data.\n",
    "    Output:\n",
    "    mse: Mean square error on test data.\n",
    "    \"\"\"\n",
    "    initial_sensor_loc = np.random.randn(7, 2) * 100\n",
    "    estimated_sensor_loc = find_mle_by_grad_descent_part_e(\n",
    "        initial_sensor_loc, Y, X, lr=0.001, num_iters=1000)\n",
    "\n",
    "    mses = []\n",
    "    for i, X_test in enumerate(Xs_test):\n",
    "        Y_test = Ys_test[i]\n",
    "        Y_pred = np.array([\n",
    "            get_object_location(estimated_sensor_loc, X_test_single)\n",
    "            for X_test_single in X_test\n",
    "        ])\n",
    "        mse = np.mean(np.sqrt(np.sum((Y_pred - Y_test)**2, axis=1)))\n",
    "        mses.append(mse)\n",
    "    return mses\n",
    "\n",
    "\n",
    "def oracle_model(X, Y, Xs_test, Ys_test, sensor_loc):\n",
    "    \"\"\"\n",
    "    This function implements the generative model.\n",
    "    Input:\n",
    "    X: independent variables in training data.\n",
    "    Y: dependent variables in training data.\n",
    "    Xs_test: independent variables in test data.\n",
    "    Ys_test: dependent variables in test data.\n",
    "    sensor_loc: location of the sensors.\n",
    "    Output:\n",
    "    mse: Mean square error on test data.\n",
    "    \"\"\"\n",
    "    mses = []\n",
    "    for i, X_test in enumerate(Xs_test):\n",
    "        Y_test = Ys_test[i]\n",
    "        Y_pred = np.array([\n",
    "            get_object_location(sensor_loc, X_test_single)\n",
    "            for X_test_single in X_test\n",
    "        ])\n",
    "        mse = np.mean(np.sqrt(np.sum((Y_pred - Y_test)**2, axis=1)))\n",
    "        mses.append(mse)\n",
    "    return mses\n",
    "\n",
    "\n",
    "def zero_model(X, Y, Xs_test, Ys_test, sensor_loc):\n",
    "    \"\"\"\n",
    "    This function implements the zero model: always predict zero\n",
    "    Input:\n",
    "    X: independent variables in training data.\n",
    "    Y: dependent variables in training data.\n",
    "    Xs_test: independent variables in test data.\n",
    "    Ys_test: dependent variables in test data.\n",
    "    sensor_loc: location of the sensors.\n",
    "    Output:\n",
    "    mse: Mean square error on test data.\n",
    "    \"\"\"\n",
    "    mses = []\n",
    "    for i, X_test in enumerate(Xs_test):\n",
    "        Y_test = Ys_test[i]\n",
    "        Y_pred = np.zeros(Y_test.shape)\n",
    "        mse = np.mean(np.sqrt(np.sum((Y_pred - Y_test)**2, axis=1)))\n",
    "        mses.append(mse)\n",
    "    return mses\n",
    "\n",
    "\n",
    "def construct_second_order_data(X):\n",
    "    \"\"\"\n",
    "    This function computes second order variables\n",
    "    for polynomial regression.\n",
    "    Input:\n",
    "    X: Independent variables.\n",
    "    Output:\n",
    "    A data matrix composed of both first and second order terms.\n",
    "    \"\"\"\n",
    "    X_second_order = []\n",
    "    m = X.shape[1]\n",
    "    for i in range(m):\n",
    "        for j in range(m):\n",
    "            if j <= i:\n",
    "                X_second_order.append(X[:, i] * X[:, j])\n",
    "    X_second_order = np.array(X_second_order).T\n",
    "    return np.concatenate((X, X_second_order), axis=1)\n",
    "\n",
    "\n",
    "def linear_regression(X, Y, Xs_test, Ys_test):\n",
    "    \"\"\"\n",
    "    This function performs linear regression.\n",
    "    Input:\n",
    "    X: independent variables in training data.\n",
    "    Y: dependent variables in training data.\n",
    "    Xs_test: independent variables in test data.\n",
    "    Ys_test: dependent variables in test data.\n",
    "    Output:\n",
    "    mse: Mean square error on test data.\n",
    "    \"\"\"\n",
    "\n",
    "    ## YOUR CODE HERE\n",
    "    ### start linReg ###\n",
    "    w = np.linalg.lstsq(X, Y)[0]\n",
    "    mses = []\n",
    "    for X_test, Y_test in zip(Xs_test, Ys_test):\n",
    "        mses.append(np.mean(np.linalg.norm(Y_test - X_test @ w)**2))\n",
    "    ### end linReg ###\n",
    "    return mses\n",
    "\n",
    "\n",
    "def poly_regression_second(X, Y, Xs_test, Ys_test):\n",
    "    \"\"\"\n",
    "    This function performs second order polynomial regression.\n",
    "    Input:\n",
    "    X: independent variables in training data.\n",
    "    Y: dependent variables in training data.\n",
    "    Xs_test: independent variables in test data.\n",
    "    Ys_test: dependent variables in test data.\n",
    "    Output:\n",
    "    mse: Mean square error on test data.\n",
    "    \"\"\"\n",
    "    ## YOUR CODE HERE\n",
    "    ### start polyReg ###\n",
    "    \n",
    "    w = np.linalg.lstsq(construct_second_order_data(X), Y)[0]\n",
    "    mses = []\n",
    "    for X_test, Y_test in zip(Xs_test, Ys_test):\n",
    "        mses.append(np.mean(np.linalg.norm(Y_test - construct_second_order_data(X_test) @ w)**2))\n",
    "    ### end polyReg ###\n",
    "    return mses\n",
    "\n",
    "\n",
    "def poly_regression_cubic(X, Y, Xs_test, Ys_test):\n",
    "    \"\"\"\n",
    "    This function performs third order polynomial regression.\n",
    "    Input:\n",
    "    X: independent variables in training data.\n",
    "    Y: dependent variables in training data.\n",
    "    Xs_test: independent variables in test data.\n",
    "    Ys_test: dependent variables in test data.\n",
    "    Output:\n",
    "    mse: Mean square error on test data.\n",
    "    \"\"\"\n",
    "    ## YOUR CODE HERE\n",
    "    ### start cubReg ###\n",
    "    mses = []\n",
    "    \n",
    "    ### end cubReg ###\n",
    "    return mses\n",
    "\n",
    "\n",
    "def neural_network(X, Y, Xs_test, Ys_test):\n",
    "    \"\"\"\n",
    "    This function performs neural network prediction.\n",
    "    Input:\n",
    "    X: independent variables in training data.\n",
    "    Y: dependent variables in training data.\n",
    "    Xs_test: independent variables in test data.\n",
    "    Ys_test: dependent variables in test data.\n",
    "    Output:\n",
    "    mse: Mean square error on test data.\n",
    "    \"\"\"\n",
    "    ## YOUR CODE HERE\n",
    "    ### start nn ###\n",
    "    mses = []\n",
    "    D_in = X.shape[1]\n",
    "    D_out = Y.shape[1]\n",
    "    H = 100\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(D_in, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(H, D_out),\n",
    "    )\n",
    "    loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "    \n",
    "    X_tensor = torch.tensor(X).float()\n",
    "    Y_tensor = torch.tensor(Y).float()\n",
    "    learning_rate = 1e-4\n",
    "    for t in range(6):\n",
    "        Y_pred = model(X_tensor)\n",
    "        loss = loss_fn(Y_pred, Y_tensor)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for param in model.parameters():\n",
    "                param -= learning_rate * param.grad\n",
    "    mses = []\n",
    "    for X_test, Y_test in zip(Xs_test, Ys_test):\n",
    "        X_test_tensor, Y_test_tensor = torch.tensor(X_test).float(), torch.tensor(Y_test).float()\n",
    "        mses.append(loss_fn(model(X_test), Y_test))\n",
    "    ### end nn ###\n",
    "    return mses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3de3hU1b3/8fdXCBBAAQElEJ4GfgewGiDElIt4bcpF8eetWkUraO3B8/MC6hGB2tpUPRarj4rH28ErbTkaSr1wGioq6hE8gCYQLl4QiiAJKAFKTkVQLuv3x+yEIZlJJplrZn9ez5NnZtZeM/s7G+Y7a9Zae21zziEiIv5wTLIDEBGRxFHSFxHxESV9EREfUdIXEfERJX0RER9pnewAGtKtWzeXk5OT7DBERFqUsrKync657qG2pXTSz8nJobS0NNlhiIi0KGa2Jdw2de+IiPiIkr6IiI8o6YuI+EhK9+mHcuDAASoqKti/f3+yQ5Ew2rVrR3Z2NhkZGckORUTqaHFJv6KigmOPPZacnBzMLNnhSB3OOXbt2kVFRQV9+vRJdjgiUkeL697Zv38/Xbt2VcJPUWZG165d9UtMJEW1uKQPKOGnOP37iDRPyaYSRs8fzaA5gxg9fzQlm0pivo8W170jIpKOSjaVUPQ/Rew/FPiVvH3vdor+pwiAcX3HxWw/LbKlLyKSbmatnFWb8GvsP7SfWStnxXQ/SvotjHOOw4cPJzsMEYmxL/d+2aTy5kr7pP/qqkpGznybPtNLGDnzbV5dVRn1a+7du5dx48YxePBgcnNzKS4upqysjLPOOotTTz2VMWPGsH37dgDOPvtspk2bxtChQ+nfvz9LliwB4KOPPmLo0KHk5eUxaNAgNmzYAMBDDz1Ebm4uubm5PPLIIwBs3ryZ73//+9xwww3k5+ezdetWrrnmGnJzcxk4cCAPP/xw1O9JRJKrR4ceTSpvrkaTvpk9Z2Y7zGxdiG23m5kzs27eYzOzR81so5mtMbP8oLoTzWyD9zcxpu8ijFdXVTLj5bVU7tmHAyr37GPGy2ujTvyvv/46PXv2ZPXq1axbt46xY8dy8803M3/+fMrKyvjZz37GnXfeWVv/4MGDfPDBBzzyyCP85je/AeCpp55iypQplJeXU1paSnZ2NmVlZTz//POsWLGC5cuX8/TTT7Nq1SoA1q9fz4QJE1i1ahU7d+6ksrKSdevWsXbtWq699tqo3o+IJN+U/Cm0a9XuqLJ2rdoxJX9KTPcTSUv/BWBs3UIz6w2MAr4IKj4X6Of9TQKe9OoeD/waGAYMBX5tZl2iCTwSDyxaz74Dh44q23fgEA8sWh/V6w4cOJC33nqLadOmsWTJErZu3cq6desYNWoUeXl53HvvvVRUVNTWv+SSSwA49dRT2bx5MwAjRozgvvvu4/7772fLli1kZmaydOlSLr74Yjp06EDHjh255JJLan8ZfO9732P48OEA9O3bl02bNnHzzTfz+uuvc9xxx0X1fkQk+cb1HUfRaUVkdcjCMLI6ZFF0WlFMB3Ehgtk7zrn3zCwnxKaHgTuA14LKLgR+7wJXW19uZp3NLAs4G3jTObcbwMzeJPBF8mJU0Tdi2559TSqPVP/+/SkrK2PhwoXMmDGDUaNGccopp7Bs2bKQ9du2bQtAq1atOHjwIABXXnklw4YNo6SkhDFjxvDMM8/Q0EXqO3ToUHu/S5curF69mkWLFvH4448zb948nnvuuajek4gk37i+42Ke5OtqVp++mV0AVDrnVtfZ1AvYGvS4wisLVx7qtSeZWamZlVZVVTUnvFo9O2c2qTxS27Zto3379vz0pz/l9ttvZ8WKFVRVVdUm/QMHDvDRRx81+BqbNm2ib9++TJ48mQsuuIA1a9Zw5pln8uqrr/LNN9+wd+9eXnnlFc4444x6z925cyeHDx/mxz/+Mffccw8rV66M6v2IiH80eZ6+mbUH7gRGh9ocosw1UF6/0LnZwGyAgoKC8E3fCEwdM4AZL689qosnM6MVU8cMiOZlWbt2LVOnTuWYY44hIyODJ598ktatWzN58mSqq6s5ePAgt9xyC6ecckrY1yguLuaPf/wjGRkZ9OjRg7vuuovjjz+ea665hqFDhwLw85//nCFDhtR2CdWorKzk2muvrZ3F89vf/jaq9yMi/mENdSnUVgp07/zFOZdrZgOBxcA33uZsYBuBvvrfAO865170nreeQNfO2cDZzrnrvfL/CK4XTkFBgat7EZVPPvmE73//+5G9OwKDuQ8sWs+2Pfvo2TmTqWMGcNGQkD8yJIaa+u8k0pKVbCph1spZfLn3S3p06MGU/Clx76ZpiJmVOecKQm1rckvfObcWOCHoxTcDBc65nWa2ALjJzF4iMGhb7ZzbbmaLgPuCBm9HAzOauu/muGhILyV5EYmbRJ1JGyuRTNl8EVgGDDCzCjO7roHqC4FNwEbgaeAGAG8A9x7gQ+/v7ppBXRGRlixRZ9LGSiSzd8Y3sj0n6L4DbgxT7zlAU0xEJK0k6kzaWEn7M3JFROIpUWfSxoqSvohIFBJ1Jm2saGllEZEINTRLJ5Vm7zREST/FdOzYka+//jph+3vqqado3749EyZMCFunvLycbdu2cd555yUsLpFU09gsnVRN8nWpeycKyV7mOBb7/5d/+ZcGEz4Ekv7ChQuj2o9IS1ayqYRfLP1Fi5qlE076J/018+DhXCjqHLhdMy+qlwu1zPEbb7zBiBEjyM/P57LLLqttqS9cuJCTTjqJ008/ncmTJ3P++ecDUFRUxIMPPlj7mrm5ufXOuv36668pLCwkPz+fgQMH8tprr4Xdf7CcnJzapZyHDh3Kxo0bAdiyZQuFhYUMGjSIwsJCvvjii3qxhFoG+rvvvuOuu+6iuLiYvLw8iouL+e///m/y8vLIy8tjyJAh/OMf/4jqmIqkspoW/mEXuoGVqrN0wknvpL9mHvzXZKjeCrjA7X9NjjrxBy9z3KFDB+69917eeustVq5cSUFBAQ899BD79+/n+uuv569//StLly6lqesItWvXjldeeYWVK1fyzjvv8K//+q+1C7IF7/973/teveced9xxfPDBB9x0003ccsstANx0001MmDCBNWvWcNVVVzF58uSQ+627DHSbNm24++67ufzyyykvL+fyyy/nwQcf5PHHH6e8vJwlS5aQmRndWkYiqSzUPPxgqTpLJ5z0TvqL74YDdVbUPLAvUB6F4GWOly9fzscff8zIkSPJy8tjzpw5bNmyhU8//ZS+ffvSp08fAMaPb/B0h3qcc/ziF79g0KBB/OhHP6KyspKvvvqq3v5DqdnX+PHjaxeBW7ZsGVdeeSUAV199NUuXLg353FDLQNc1cuRIbrvtNh599FH27NlD69YaGpL0EOrC5A215FN5lk446f1pra5oWnmEgpc5ds4xatQoXnzx6GWEai5+Ekrr1q2P6ovfv79+K2Lu3LlUVVVRVlZGRkYGOTk5tfWC9x+KmYW8H65OsFDLQNc1ffp0xo0bx8KFCxk+fDhvvfUWJ510UoMxiaS6cAO1x7U5jurvquvVP8aOict69/GW3i39TtlNK2+G4cOH8/7779f2nX/zzTd89tlnnHTSSWzatKm2tVxcXFz7nJycnNrlkFeuXMnnn39e73Wrq6s54YQTyMjI4J133mHLli0Rx1Szr+LiYkaMGAHAaaedxksvvQQEvlBOP/30iF/v2GOPParf/m9/+xsDBw5k2rRpFBQU8Omnn0b8WiKpKtxyCmYWch7+faff1+ISPqR70i+8CzLq9DdnZAbKY6R79+688MILjB8/nkGDBjF8+HA+/fRTMjMzeeKJJxg7diynn346J554Ip06dQLgxz/+Mbt37yYvL48nn3yS/v3713vdq666itLSUgoKCpg7d26TWtLffvstw4YNY9asWbXXz3300Ud5/vnnGTRoEH/4wx+YNSvyGQfnnHMOH3/8ce1A7iOPPEJubi6DBw8mMzOTc889N+LXEklV4bpxqr+tTsgVrRIloqWVkyUWSyuzZl6gD7+6ItDCL7wLBv0kxpGG9vXXX9OxY0ecc9x4443069ePW2+9Na77zMnJobS0lG7dusV1P43R0srS0oyeP5rte7fXK8/qkMUbl76RhIiaL6ZLK7c4g36SsCRf19NPP82cOXP47rvvGDJkCNdff31S4hCRxk3Jn3JUnz60zIHaxqR/0k+iW2+9Ne4t+7rCzbgRkYa1tOUUmktJX0TSUsmmEmZ+MJM93+4BoFObTswYNqPBJN6SllNorvQeyBURXyrZVMKv3v9VbcIHqP6umulLpvPPi/45iZEln5K+iKSdmR/M5MDhAyG3Lf9yOfcuvzfBEaWOSC6X+JyZ7TCzdUFlD5jZp2a2xsxeMbPOQdtmmNlGM1tvZmOCysd6ZRvNbHrs34qISKCVH9zCD+VPn/0pQdGknkha+i8AY+uUvQnkOucGAZ/hXeTczE4GrgBO8Z7zhJm1MrNWwOPAucDJwHivbtrIyclh586d9coXLFjAzJkzAaiqqmLYsGEMGTKEJUuWcN999zV5Py+88AI33XRT1PFu27aNSy+9tNF6zYlRJJkiWfUy3OJpftBo0nfOvQfsrlP2hnOu5hz95UDNKa4XAi855751zn1O4ALpQ72/jc65Tc6574CXvLpp74ILLmD69MAPm8WLF3PSSSexatUqzjjjjKQm1J49ezJ//vxG6ynpS0sTaq59XceYf3u2Y/HOfwb81bvfCwhe67fCKwtXXo+ZTTKzUjMrberKlKGEWkApGnv37mXcuHEMHjyY3Nzco5ZX+Pd///fapZBrliaoaZmXl5dzxx13sHDhQvLy8pg2bRr79u0jLy+Pq666CoA//vGPDB06lLy8PK6//noOHToEwPPPP0///v0566yzeP/990PGVVRUxNVXX80Pf/hD+vXrx9NPPw0E1gaaOnUqubm5DBw4sDbezZs3k5ubWxvjJZdcwtixY+nXrx933HEHEFhjJzjGht67SLKVbCrhjJfOiKjuZf0vi3M0qSuqKZtmdidwEJhbUxSimiP0l0vIU4Gdc7OB2RA4Izea+Bq70k1zvP766/Ts2ZOSksCXR3X1kYWYunXrxsqVK3niiSd48MEHeeaZZ2q35eXlcffdd1NaWspjjz0GULs8MQTOYC0uLub9998nIyODG264gblz5zJq1Ch+/etfU1ZWRqdOnTjnnHMYMmRIyNjWrFnD8uXL2bt3L0OGDGHcuHEsW7aM8vJyVq9ezc6dO/nBD37AmWeeWe+55eXlrFq1irZt2zJgwABuvvlmZs6cyWOPPVYb45///Oew710kmep+1sM5xo7hsv6X8cvhv0xQZKmn2S19M5sInA9c5Y6s5VAB9A6qlg1sa6A8rsItoBTNlW4GDhzIW2+9xbRp01iyZEntejoQ2bLE4SxevJiysjJ+8IMfkJeXx+LFi9m0aRMrVqzg7LPPpnv37rRp04bLL7887GtceOGFZGZm0q1bN8455xw++OADli5dyvjx42nVqhUnnngiZ511Fh9++GG95xYWFtKpUyfatWvHySefHHKBt4beu0gyNbbmPcDaiWtZPWG1rxM+NDPpm9lYYBpwgXPum6BNC4ArzKytmfUB+gEfAB8C/cysj5m1ITDYuyC60BsXbgGlaK50079/f8rKyhg4cCAzZszg7ruPrM0fybLE4TjnmDhxIuXl5ZSXl7N+/XqKioqA8Msg11W3npkR6dpKNbFD+Pgbeu8iydTYZzqrQ1aCIkl9kUzZfBFYBgwwswozuw54DDgWeNPMys3sKQDn3EfAPOBj4HXgRufcIW/Q9yZgEfAJMM+rG1fhrmgTzZVutm3bRvv27fnpT3/K7bffXrtEcnNkZGRw4EBgLnFhYSHz589nx44dAOzevZstW7YwbNgw3n33XXbt2sWBAwf405/CTzV77bXX2L9/P7t27eLdd9+t7copLi7m0KFDVFVV8d577zF06NBmxRjL9y4STrhxuIbG5xr6TKfj+jnRaLRP3zkX6pJPzzZQ/9+AfwtRvhBI6NW147GA0tq1a5k6dSrHHHMMGRkZPPnkk81+rUmTJjFo0CDy8/OZO3cu9957L6NHj+bw4cNkZGTw+OOPM3z4cIqKihgxYgRZWVnk5+fXDvDWNXToUMaNG8cXX3zBr371K3r27MnFF1/MsmXLGDx4MGbG7373O3r06BFx91NwjBMmTIjZexcJJdQ43PQl05m+5OhTe+qOz4X6rENkSy/4TdovrVyyqSTtF1CCwOydjh07cvvttyc7FEBLK0vzhFveOJzgZY/98lmPhK+XVvbDAkoi6aKp423B9fVZj0zaJ32/qBn0FWnJenTo0aSWfjTjc37VIk9LS+UuKdG/jzTflPwp9a5HG44GaJunxbX027Vrx65du+jatWvEUxklcZxz7Nq1i3btIvvgisDR/fGd2naibau2VH8X/uS/rA5Zvu6zj0aLS/rZ2dlUVFQQiyUaJD7atWtHdnZ24xVFgHuX30vx+iNLeuz5dg/tWrXj8gGX8/KGl49aIjnjmAzuGXmPkn0UWlzSz8jIoE+fPskOQ0RioGRTyVEJv8b+Q/t5r+I97hl5j2bkxFiLS/oikj4aWhJl+97tmpETBy1yIFdE0kNDUzT9vPxxPOmoikjSNDTl0s8XOoknJX0Ribtw6+Y0NOVSi6TFh/r0RSSuGruuxaodq+oN5moOfvyopS8icdXYdS1+OfyXzDxjJlkdsjCMrA5ZFJ1WpAHcOFFLX0TiKpLrWmiWTuKopS8icRWP61pI8ynpi0hchVpPR332yRPJlbOeM7MdZrYuqOx4M3vTzDZ4t128cjOzR81so5mtMbP8oOdM9Opv8K6vKyI+MK7vOIpOK1KffYpo9CIqZnYm8DXwe+dcrlf2O2C3c26mmU0HujjnppnZecDNwHnAMGCWc26YmR0PlAIFgAPKgFOdc39vaN+hLqIiIiINa+giKo229J1z7wG76xRfCMzx7s8BLgoq/70LWA50NrMsYAzwpnNut5fo3wTGNv2tiIhINJrbp3+ic247gHd7glfeC9gaVK/CKwtXLiIiCRTrgdxQC9y7Bsrrv4DZJDMrNbNSLZ8sIhJbzU36X3ndNni3O7zyCqB3UL1sYFsD5fU452Y75wqccwXdu3dvZngiIhJKc5P+AqBmBs5E4LWg8gneLJ7hQLXX/bMIGG1mXbyZPqO9MhERSaBGz8g1sxeBs4FuZlYB/BqYCcwzs+uAL4DLvOoLCczc2Qh8A1wL4JzbbWb3AB969e52ztUdHBYRkThrdMpmMmnKpohI00U1ZVNERNKHkr6IiI8o6YuI+IiSvoiIjyjpi4j4iJK+iIiPKOmLiPiIkr6IiI8o6YuI+IiSvoiIjyjpi4j4iJK+iIiPKOmLiPiIkr6IiI8o6YuI+IiSvoiIjyjpi4j4SFRJ38xuNbOPzGydmb1oZu3MrI+ZrTCzDWZWbGZtvLptvccbve05sXgDIiISuWYnfTPrBUwGCpxzuUAr4ArgfuBh51w/4O/Add5TrgP+7pz7J+Bhr56IiCRQtN07rYFMM2sNtAe2Az8E5nvb5wAXefcv9B7jbS80M4ty/yIi0gTNTvrOuUrgQeALAsm+GigD9jjnDnrVKoBe3v1ewFbvuQe9+l3rvq6ZTTKzUjMrraqqam54IiISQjTdO10ItN77AD2BDsC5Iaq6mqc0sO1IgXOznXMFzrmC7t27Nzc8EREJIZrunR8BnzvnqpxzB4CXgdOAzl53D0A2sM27XwH0BvC2dwJ2R7F/ERFpomiS/hfAcDNr7/XNFwIfA+8Al3p1JgKvefcXeI/xtr/tnKvX0hcRkfiJpk9/BYEB2ZXAWu+1ZgPTgNvMbCOBPvtnvac8C3T1ym8DpkcRt4iINIOlcmO7oKDAlZaWJjsMEZEWxczKnHMFobbpjFwRER9R0hcR8RElfRERH1HSFxHxESV9EREfUdIXEfERJX0RER9R0hcR8RElfRERH1HSFxHxESV9EREfUdIXEfERJX0RER9R0hcR8RElfRERH1HSFxHxESV9EREfiSrpm1lnM5tvZp+a2SdmNsLMjjezN81sg3fbxatrZvaomW00szVmlh+btyAiIpGKtqU/C3jdOXcSMBj4hMC1bxc75/oBizlyLdxzgX7e3yTgySj3LSIiTdTspG9mxwFn4l343Dn3nXNuD3AhMMerNge4yLt/IfB7F7Ac6GxmWc2OXEREmiyaln5foAp43sxWmdkzZtYBONE5tx3Auz3Bq98L2Br0/Aqv7ChmNsnMSs2stKqqKorwRESkrmiSfmsgH3jSOTcE2MuRrpxQLESZq1fg3GznXIFzrqB79+5RhCciInVFk/QrgArn3Arv8XwCXwJf1XTbeLc7gur3Dnp+NrAtiv2LiEgTNTvpO+e+BLaa2QCvqBD4GFgATPTKJgKvefcXABO8WTzDgeqabiAREUmM1lE+/2Zgrpm1ATYB1xL4IplnZtcBXwCXeXUXAucBG4FvvLoiIpJAUSV951w5UBBiU2GIug64MZr9iYhIdHRGroiIjyjpi4j4iJK+iIiPKOmLiPiIkr6IiI8o6YuI+IiSvoiIjyjpi4j4iJK+X62ZBw/nQlHnwO2aecmOSEQSINplGKQlWjMP/msyHNgXeFy9NfAYYNBPkheXiMSdWvp+tPjuIwm/xoF9gXIRSWtK+n5UXdG0chFJG0r6ftQpu2nlIpI2lPT9qPAuyMg8uiwjM1AuImlNA7l+sWZeoM++uiLQoh98JWx448jjwrs0iCviA0r6fhBqts7q/4T/+6gSvYjPRN29Y2atzGyVmf3Fe9zHzFaY2QYzK/auqoWZtfUeb/S250S7b4mQZuuIiCcWffpTgE+CHt8PPOyc6wf8HbjOK78O+Ltz7p+Ah716/pToE6M0W0dEPFElfTPLBsYBz3iPDfghMN+rMge4yLt/ofcYb3uhV99farpaqrcC7siJUfFM/LGeraOzeUVarGhb+o8AdwCHvcddgT3OuYPe4wqgl3e/F7AVwNte7dU/iplNMrNSMyutqqqKMrwUlIyulljO1knGl5aIxEyzk76ZnQ/scM6VBReHqOoi2HakwLnZzrkC51xB9+7dmxte6opVV0tTWtuDfhIYtO3UG7DAbXMHcTU+INKiRTN7ZyRwgZmdB7QDjiPQ8u9sZq291nw2sM2rXwH0BirMrDXQCdgdxf5bpk7ZXis5RHmkmrN2zqCfxGamjsYHRFq0Zrf0nXMznHPZzrkc4ArgbefcVcA7wKVetYnAa979Bd5jvO1vO+fqtfTTXiy6Wprb2o5FX7zO5hVp0eJxRu404DYz20igz/5Zr/xZoKtXfhswPQ77Tn2x6GppTms7Vn3xOptXpEWzVG5sFxQUuNLS0mSHkXoezg3TRdQbbl0Xu+eEU/fsXp3NK5JSzKzMOVcQapvOyG2JCu86uk8fGm9tx7IvPlbjAyKScFpwrSVqTheR+uJFBLX0kyMW3SNNbW0359eBiKQdJf1Ea8p0y1j2ndc8T33xIr6mgdxYayxRRzqgWvfLAQItc62MKSKNaGggV336sRTJtMhIB1R15quIxIGSfixFkqgbG1CtOYEq1K8B0JmvIhIVJf1YiqQV39DJTUf9UghDs21EJApK+rEUybTIhqZbhvqlECzes220ZLJI2tPsnVhqbFpk3UHeS2YfPSjbUNdNp95HXufh3NADxdHM9mnOIm4i0uIo6cdSQ9MiI0mqYVfg9Gb2NPQaEF3Sbmg8QklfJG0o6dcV7dz4cCdNNTbIu/huL+EbR11mIPiXQmOvEU3S1pLJIr6gpB8snl0cYZPq1jpdQo7axF/TpVOz7+Yk5kiTdizW+ReRlKeB3GDxnBsfLnlaqxCDt+5Il07wl01DA8XRrq2jJZNFfEFJP1gDLelXV1Uycubb9JlewsiZb/PqqsqmvXa4pOoORR5LQ4k52qQdy0sqikjKUvdOsDBdHN9k9mDGy2vZdyCQoCv37GPGy2sBuGhIr3r1Qwo3yFvblx8ilkhfIzgxx2M8QkTShpJ+sDBTLn934PLahF9j34FDPLBofcNJP9SgcKgLljRl9cuGErOStog0otlJ38x6A78HegCHgdnOuVlmdjxQDOQAm4GfOOf+bmYGzALOA74BrnHOrYwu/BgL05Ke858dQlbftsdL1KGSO0Q2KKzVL0UkgZq9yqaZZQFZzrmVZnYsUAZcBFwD7HbOzTSz6UAX59w0MzsPuJlA0h8GzHLODWtoH6myyubImW9Tuaf+mbK9Omfy/nk7Q7fUW2fCvt31X6w5lycUEWmCuKyy6ZzbXtNSd879A/gE6AVcCMzxqs0h8EWAV/57F7Ac6Ox9caS8qWMGkJnR6qiyzIxWTB0zIPyMn1AJHzTvXUSSKiazd8wsBxgCrABOdM5th8AXA3CCV60XEDxiWeGV1X2tSWZWamalVVVVsQgvahcN6cVvLxlIr86ZGIEW/m8vGRjoz29qEte8dxFJoqgHcs2sI/Bn4Bbn3P8Guu5DVw1RVq9vyTk3G5gNge6daOOLlYuG9Ao9aBvupKbM4+HgPl2eUERSSlQtfTPLIJDw5zrnXvaKv6rptvFud3jlFUDvoKdnA9ui2X9KCDc//tz7Ne9dRFJONLN3DHgW+MQ591DQpgXARGCmd/taUPlNZvYSgYHc6ppuoBatsdk3SvIikkKi6d4ZCVwNrDWzcq/sFwSS/Twzuw74ArjM27aQwMydjQSmbF4bxb6b7NVVlTywaD3b9uyjZ+dMpo4ZEPmJVY3R/HgRaSGanfSdc0sJ3U8PUBiivgNubO7+ovHqqsroz6gVEUkDvlh754FF68OeUSsi4ie+SPrbQpxY1VC5iEi68kXS79k5s0nlIiLpyhdJv8EzaiOli4aLSBrwRdJv8IzaSNRcUat6K+ACty9PgqJO+gIQkRbFN0srhz2jNhKh1tepOZk4lpdUFBGJM1+09KPW2Po6sbqkoohInCnpRyKSRdK0eqaItABK+pEItb5OXVo9U0RaACX9SBx10XCodyKyVs8UkRbCNwO5UQteXyfU5RE1iCsiLUBaJv24Lq4GzVpgLe4xiYhEIO2SfiourpaKMZSAHRMAAAc/SURBVImIP6Vdn34qLq6WijGJiD+lXdJPxcXVUjEmEfGntOve6dk5k8oQybSpi6vFsg8+VjGJiEQr4S19MxtrZuvNbKOZTY/168dicbWaPvjKPftwHOmDf3VVZdJiEhGJhYQmfTNrBTwOnAucDIw3s5NjuY+oF1cj9n3wsYhJRCQWLHAVwwTtzGwEUOScG+M9ngHgnPttqPoFBQWutLQ0YfHV6DO9hHBHxUBTLkUkpZlZmXOuINS2RHfv9AK2Bj2u8MpqmdkkMys1s9KqqqqEBlejob72WHT3iIgkS6KTfqgLqR/VqHbOzXbOFTjnCrp3756gsI4Wqg++Lk25FJGWKNGzdyqA3kGPs4FtCY6hUTXdNjWzd8J19WjKpYi0NIlO+h8C/cysD1AJXAFcmeAYIhJ80ZWRM9/WlEsRSQsJ7d5xzh0EbgIWAZ8A85xzHyUyhubQlEsRSRcJPznLObcQWJjo/UajbnePZu+ISEuVdmfkxktU19gVEUkRabf2joiIhKekLyLiI0r6IiI+oj79BNMVtEQkmZT0E0hX0BKRZFP3TgLpCloikmxK+gmkK2iJSLIp6SdQuGUbtJyDiCSKkn4CaTkHEUk2DeQmkJZzEJFkU9JPMC3nICLJpO4dEREfUdIXEfERJX0RER9R0hcR8RElfRERHzHnwl32O/nMrArYEoOX6gbsjMHrxIvii47ii47ii04qxvc951z3UBtSOunHipmVOucKkh1HOIovOoovOoovOqkeX13q3hER8RElfRERH/FL0p+d7AAaofiio/iio/iik+rxHcUXffoiIhLgl5a+iIigpC8i4itpnfTNbKyZrTezjWY2PUkx9Dazd8zsEzP7yMymeOXHm9mbZrbBu+3ilZuZPerFvMbM8hMUZyszW2Vmf/Ee9zGzFV58xWbWxitv6z3e6G3PSUBsnc1svpl96h3HEal0/MzsVu/fdp2ZvWhm7ZJ5/MzsOTPbYWbrgsqafLzMbKJXf4OZTYxzfA94/75rzOwVM+sctG2GF996MxsTVB6Xz3eo+IK23W5mzsy6eY8Tfvyi5pxLyz+gFfA3oC/QBlgNnJyEOLKAfO/+scBnwMnA74DpXvl04H7v/nnAXwEDhgMrEhTnbcB/An/xHs8DrvDuPwX8P+/+DcBT3v0rgOIExDYH+Ll3vw3QOVWOH9AL+BzIDDpu1yTz+AFnAvnAuqCyJh0v4Hhgk3fbxbvfJY7xjQZae/fvD4rvZO+z2xbo432mW8Xz8x0qPq+8N7CIwAmj3ZJ1/KJ+f8kOIG5vDEYAi4IezwBmpEBcrwGjgPVAlleWBaz37v8HMD6ofm29OMaUDSwGfgj8xfsPvDPoQ1h7LL3/9CO8+629ehbH2I7zkqrVKU+J40cg6W/1PtytveM3JtnHD8ipk1SbdLyA8cB/BJUfVS/W8dXZdjEw17t/1Oe25vjF+/MdKj5gPjAY2MyRpJ+U4xfNXzp379R8GGtUeGVJ4/2UHwKsAE50zm0H8G5P8KolI+5HgDuAw97jrsAe59zBEDHUxudtr/bqx0tfoAp43ut+esbMOpAix885Vwk8CHwBbCdwPMpIneNXo6nHK5mfn58RaD3TQBwJjc/MLgAqnXOr62xKifiaIp2TvoUoS9r8VDPrCPwZuMU5978NVQ1RFre4zex8YIdzrizCGBJ9XFsT+Kn9pHNuCLCXQPdEOIk+fl2ACwl0PfQEOgDnNhBDSv2/JHw8SYnTzO4EDgJza4rCxJGw+MysPXAncFeozWHiSLV/51rpnPQrCPTB1cgGtiUjEDPLIJDw5zrnXvaKvzKzLG97FrDDK0903COBC8xsM/ASgS6eR4DOZlZzOc3gGGrj87Z3AnbHMb4KoMI5t8J7PJ/Al0CqHL8fAZ8756qccweAl4HTSJ3jV6Opxyvhnx9vsPN84Crn9YmkSHz/h8CX+mrvc5INrDSzHikSX5Okc9L/EOjnzaJoQ2DQbEGigzAzA54FPnHOPRS0aQFQM6I/kUBff035BG9WwHCguuZneTw452Y457KdczkEjtHbzrmrgHeAS8PEVxP3pV79uLVgnHNfAlvNbIBXVAh8TIocPwLdOsPNrL33b10TX0ocvyBNPV6LgNFm1sX7NTPaK4sLMxsLTAMucM59UyfuK7xZT32AfsAHJPDz7Zxb65w7wTmX431OKghMzviSFDl+TZLsQYV4/hEYWf+MwCj/nUmK4XQCP+vWAOXe33kE+nEXAxu82+O9+gY87sW8FihIYKxnc2T2Tl8CH66NwJ+Atl55O+/xRm973wTElQeUesfwVQKzIVLm+AG/AT4F1gF/IDDTJGnHD3iRwPjCAQIJ6rrmHC8Cfesbvb9r4xzfRgJ94DWfkaeC6t/pxbceODeoPC6f71Dx1dm+mSMDuQk/ftH+aRkGEREfSefuHRERqUNJX0TER5T0RUR8RElfRMRHlPRFRHxESV9ExEeU9EVEfOT/A7sO/Y1WdVTeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot 0\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "sensor_loc = generate_sensors()\n",
    "regular_loc, _ = generate_dataset(\n",
    "    sensor_loc,\n",
    "    num_sensors=sensor_loc.shape[0],\n",
    "    spatial_dim=2,\n",
    "    num_data=20,\n",
    "    original_dist=True,\n",
    "    noise=1)\n",
    "shifted_loc, _ = generate_dataset(\n",
    "    sensor_loc,\n",
    "    num_sensors=sensor_loc.shape[0],\n",
    "    spatial_dim=2,\n",
    "    num_data=20,\n",
    "    original_dist=False,\n",
    "    noise=1)\n",
    "\n",
    "plt.scatter(sensor_loc[:, 0], sensor_loc[:, 1], label=\"sensors\")\n",
    "plt.scatter(regular_loc[:, 0], regular_loc[:, 1], label=\"regular points\")\n",
    "plt.scatter(shifted_loc[:, 0], shifted_loc[:, 1], label=\"shifted points\")\n",
    "plt.legend()\n",
    "plt.savefig(\"dataset.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot 1\n",
    "np.random.seed(0)\n",
    "ns = np.arange(10, 310, 20)\n",
    "replicates = 5\n",
    "num_methods = 7\n",
    "num_sets = 3\n",
    "mses = np.zeros((len(ns), replicates, num_methods, num_sets))\n",
    "def generate_data(sensor_loc, k=7, d=2, n=1, original_dist=True, noise=1):\n",
    "    return generate_dataset(\n",
    "        sensor_loc,\n",
    "        num_sensors=k,\n",
    "        spatial_dim=d,\n",
    "        num_data=n,\n",
    "        original_dist=original_dist,\n",
    "        noise=noise)\n",
    "for s in range(replicates):\n",
    "    sensor_loc = generate_sensors()\n",
    "    X_test, Y_test = generate_data(sensor_loc, n=1000)\n",
    "    X_test2, Y_test2 = generate_data(\n",
    "        sensor_loc, n=1000, original_dist=False)\n",
    "    for t, n in enumerate(ns):\n",
    "        X, Y = generate_data(sensor_loc, n=n)  # X [n * 2] Y [n * 7]\n",
    "        Xs_test, Ys_test = [X, X_test, X_test2], [Y, Y_test, Y_test2]\n",
    "        ### Linear regression:\n",
    "        mse = linear_regression(X, Y, Xs_test, Ys_test)\n",
    "        mses[t, s, 0] = mse\n",
    "        ### Second-order Polynomial regression:\n",
    "        mse = poly_regression_second(X, Y, Xs_test, Ys_test)\n",
    "        mses[t, s, 1] = mse\n",
    "#         ### 3rd-order Polynomial regression:\n",
    "#         mse = poly_regression_cubic(X, Y, Xs_test, Ys_test)\n",
    "#         mses[t, s, 2] = mse\n",
    "        ### Neural Network:\n",
    "        mse = neural_network(X, Y, Xs_test, Ys_test)\n",
    "        mses[t, s, 3] = mse\n",
    "#         ### Generative model:\n",
    "#         mse = generative_model(X, Y, Xs_test, Ys_test)\n",
    "#         mses[t, s, 4] = mse\n",
    "#         ### Oracle model:\n",
    "#         mse = oracle_model(X, Y, Xs_test, Ys_test, sensor_loc)\n",
    "#         mses[t, s, 5] = mse\n",
    "#         ### Zero model:\n",
    "#         mse = zero_model(X, Y, Xs_test, Ys_test, sensor_loc)\n",
    "#         mses[t, s, 6] = mse\n",
    "        print('{}th Experiment with {} samples done...'.format(s, n))\n",
    "### Plot MSE for each model.\n",
    "plt.figure()\n",
    "regressors = [\n",
    "    'Linear Regression', '2nd-order Polynomial Regression',\n",
    "    '3rd-order Polynomial Regression', 'Neural Network',\n",
    "    'Generative Model', 'Oracle Model', 'Zero Model'\n",
    "]\n",
    "for a in range(7):\n",
    "    plt.plot(ns, np.mean(mses[:, :, a, 0], axis=1), label=regressors[a])\n",
    "plt.title('Error on training data for Various models')\n",
    "plt.xlabel('Number of training data')\n",
    "plt.ylabel('Average Error')\n",
    "plt.legend(loc='best')\n",
    "plt.yscale('log')\n",
    "plt.savefig('train_mse.png')\n",
    "plt.show()\n",
    "plt.figure()\n",
    "for a in range(7):\n",
    "    plt.plot(ns, np.mean(mses[:, :, a, 1], axis=1), label=regressors[a])\n",
    "plt.title(\n",
    "    'Error on test data from the same distribution for Various models')\n",
    "plt.xlabel('Number of training data')\n",
    "plt.ylabel('Average Error')\n",
    "plt.legend(loc='best')\n",
    "plt.yscale('log')\n",
    "plt.savefig('val_same_mse.png')\n",
    "plt.show()\n",
    "plt.figure()\n",
    "for a in range(7):\n",
    "    plt.plot(ns, np.mean(mses[:, :, a, 2], axis=1), label=regressors[a])\n",
    "plt.title(\n",
    "    'Error on test data from a different distribution for Various models')\n",
    "plt.xlabel('Number of training data')\n",
    "plt.ylabel('Average Error')\n",
    "plt.legend(loc='best')\n",
    "plt.yscale('log')\n",
    "plt.savefig('val_different_mse.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 2\n",
    "def neural_network(X, Y, X_test, Y_test, num_neurons, activation):\n",
    "    \"\"\"\n",
    "    This function performs neural network prediction.\n",
    "    Input:\n",
    "    X: independent variables in training data.\n",
    "    Y: dependent variables in training data.\n",
    "    X_test: independent variables in test data.\n",
    "    Y_test: dependent variables in test data.\n",
    "    Output:\n",
    "    mse: Mean square error on test data.\n",
    "    \"\"\"\n",
    "    mse = 0\n",
    "    ### start nn2 ###\n",
    "\n",
    "    ### end nn2 ###\n",
    "    return mse\n",
    "\n",
    "#############################################################################\n",
    "#######################PLOT PART 2###########################################\n",
    "#############################################################################\n",
    "def generate_data(sensor_loc, k=7, d=2, n=1, original_dist=True, noise=1):\n",
    "    return generate_dataset(\n",
    "        sensor_loc,\n",
    "        num_sensors=k,\n",
    "        spatial_dim=d,\n",
    "        num_data=n,\n",
    "        original_dist=original_dist,\n",
    "        noise=noise)\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "n = 200\n",
    "num_neuronss = np.arange(100, 550, 50)\n",
    "mses = np.zeros((len(num_neuronss), 2))\n",
    "\n",
    "# for s in range(replicates):\n",
    "\n",
    "sensor_loc = generate_sensors()\n",
    "X, Y = generate_data(sensor_loc, n=n)  # X [n * 2] Y [n * 7]\n",
    "X_test, Y_test = generate_data(sensor_loc, n=1000)\n",
    "for t, num_neurons in enumerate(num_neuronss):\n",
    "    ### Neural Network:\n",
    "    mse = neural_network(X, Y, X_test, Y_test, num_neurons, ReLUActivation)\n",
    "    mses[t, 0] = mse\n",
    "\n",
    "    mse = neural_network(X, Y, X_test, Y_test, num_neurons, TanhActivation)\n",
    "    mses[t, 1] = mse\n",
    "\n",
    "    # print('{}th Experiment with {} samples done...'.format(s, n))\n",
    "    print('Experiment with {} neurons done...'.format(num_neurons))\n",
    "\n",
    "### Plot MSE for each model.\n",
    "plt.figure()\n",
    "activation_names = ['ReLU', 'Tanh']\n",
    "for a in range(2):\n",
    "    plt.plot(num_neuronss, mses[:, a], label=activation_names[a])\n",
    "\n",
    "plt.title('Error on validation data verses number of neurons')\n",
    "plt.xlabel('Number of neurons')\n",
    "plt.ylabel('Average Error')\n",
    "plt.legend(loc='best')\n",
    "plt.yscale('log')\n",
    "plt.savefig('num_neurons.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 3\n",
    "\n",
    "def neural_network(X, Y, X_test, Y_test, num_layers, activation):\n",
    "    \"\"\"\n",
    "    This function performs neural network prediction.\n",
    "    Input:\n",
    "    X: independent variables in training data.\n",
    "    Y: dependent variables in training data.\n",
    "    X_test: independent variables in test data.\n",
    "    Y_test: dependent variables in test data.\n",
    "    Output:\n",
    "    mse: Mean square error on test data.\n",
    "    \"\"\"\n",
    "    ### start nn3 ###\n",
    "\n",
    "    ### end nn3 ###\n",
    "    return mse\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#######################PLOT PART 2###########################################\n",
    "#############################################################################\n",
    "def generate_data(sensor_loc, k=7, d=2, n=1, original_dist=True, noise=1):\n",
    "    return generate_dataset(\n",
    "        sensor_loc,\n",
    "        num_sensors=k,\n",
    "        spatial_dim=d,\n",
    "        num_data=n,\n",
    "        original_dist=original_dist,\n",
    "        noise=noise)\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "n = 200\n",
    "num_layerss = [1, 2, 3, 4]\n",
    "mses = np.zeros((len(num_layerss), 2))\n",
    "\n",
    "# for s in range(replicates):\n",
    "sensor_loc = generate_sensors()\n",
    "X, Y = generate_data(sensor_loc, n=n)  # X [n * 2] Y [n * 7]\n",
    "X_test, Y_test = generate_data(sensor_loc, n=1000)\n",
    "for t, num_layers in enumerate(num_layerss):\n",
    "    ### Neural Network:\n",
    "    mse = neural_network(X, Y, X_test, Y_test, num_layers, ReLUActivation)\n",
    "    mses[t, 0] = mse\n",
    "\n",
    "    mse = neural_network(X, Y, X_test, Y_test, num_layers, TanhActivation)\n",
    "    mses[t, 1] = mse\n",
    "\n",
    "    # print('{}th Experiment with {} samples done...'.format(s, n))\n",
    "    print('Experiment with {} layers done...'.format(num_layers))\n",
    "\n",
    "### Plot MSE for each model.\n",
    "plt.figure()\n",
    "activation_names = ['ReLU', 'Tanh']\n",
    "for a in range(2):\n",
    "    plt.plot(num_layerss, mses[:, a], label=activation_names[a])\n",
    "\n",
    "plt.title('Error on validation data verses number of neurons')\n",
    "plt.xlabel('Number of layers')\n",
    "plt.ylabel('Average Error')\n",
    "plt.legend(loc='best')\n",
    "plt.yscale('log')\n",
    "plt.savefig('num_layers.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot4\n",
    "\n",
    "def neural_network(X, Y, Xs_test, Ys_test):\n",
    "    \"\"\"\n",
    "    This function performs neural network prediction.\n",
    "    Input:\n",
    "    X: independent variables in training data.\n",
    "    Y: dependent variables in training data.\n",
    "    X_test: independent variables in test data.\n",
    "    Y_test: dependent variables in test data.\n",
    "    Output:\n",
    "    mse: Mean square error on test data.\n",
    "    \"\"\"\n",
    "    mses = 0\n",
    "    ### start nn4 ###\n",
    "\n",
    "    ### end nn4 ###\n",
    "    return mses\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#######################PLOT PART 1###########################################\n",
    "#############################################################################\n",
    "np.random.seed(0)\n",
    "\n",
    "ns = np.arange(10, 310, 20)\n",
    "replicates = 5\n",
    "num_methods = 6\n",
    "num_sets = 3\n",
    "mses = np.zeros((len(ns), replicates, num_methods, num_sets))\n",
    "\n",
    "def generate_data(sensor_loc, k=7, d=2, n=1, original_dist=True, noise=1):\n",
    "    return generate_dataset(\n",
    "        sensor_loc,\n",
    "        num_sensors=k,\n",
    "        spatial_dim=d,\n",
    "        num_data=n,\n",
    "        original_dist=original_dist,\n",
    "        noise=noise)\n",
    "\n",
    "for s in range(replicates):\n",
    "    sensor_loc = generate_sensors()\n",
    "    X_test, Y_test = generate_data(sensor_loc, n=1000)\n",
    "    X_test2, Y_test2 = generate_data(\n",
    "        sensor_loc, n=1000, original_dist=False)\n",
    "    for t, n in enumerate(ns):\n",
    "        X, Y = generate_data(sensor_loc, n=n)  # X [n * 2] Y [n * 7]\n",
    "        Xs_test, Ys_test = [X, X_test, X_test2], [Y, Y_test, Y_test2]\n",
    "        ### Linear regression:\n",
    "        mse = linear_regression(X, Y, Xs_test, Ys_test)\n",
    "        mses[t, s, 0] = mse\n",
    "\n",
    "        ### Second-order Polynomial regression:\n",
    "        mse = poly_regression_second(X, Y, Xs_test, Ys_test)\n",
    "        mses[t, s, 1] = mse\n",
    "\n",
    "        ### 3rd-order Polynomial regression:\n",
    "        mse = poly_regression_cubic(X, Y, Xs_test, Ys_test)\n",
    "        mses[t, s, 2] = mse\n",
    "\n",
    "        ### Neural Network:\n",
    "        mse = neural_network(X, Y, Xs_test, Ys_test)\n",
    "        mses[t, s, 3] = mse\n",
    "\n",
    "        ### Generative model:\n",
    "        mse = generative_model(X, Y, Xs_test, Ys_test)\n",
    "        mses[t, s, 4] = mse\n",
    "\n",
    "        ### Oracle model:\n",
    "        mse = oracle_model(X, Y, Xs_test, Ys_test, sensor_loc)\n",
    "        mses[t, s, 5] = mse\n",
    "\n",
    "        print('{}th Experiment with {} samples done...'.format(s, n))\n",
    "\n",
    "### Plot MSE for each model.\n",
    "plt.figure()\n",
    "regressors = [\n",
    "    'Linear Regression', '2nd-order Polynomial Regression',\n",
    "    '3rd-order Polynomial Regression', 'Neural Network',\n",
    "    'Generative Model', 'Oracle Model'\n",
    "]\n",
    "for a in range(6):\n",
    "    plt.plot(ns, np.mean(mses[:, :, a, 0], axis=1), label=regressors[a])\n",
    "\n",
    "plt.title('Error on training data for Various models')\n",
    "plt.xlabel('Number of training data')\n",
    "plt.ylabel('Average Error')\n",
    "plt.legend(loc='best')\n",
    "plt.yscale('log')\n",
    "plt.savefig('best_train_mse.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "for a in range(6):\n",
    "    plt.plot(ns, np.mean(mses[:, :, a, 1], axis=1), label=regressors[a])\n",
    "\n",
    "plt.title(\n",
    "    'Error on test data from the same distribution for Various models')\n",
    "plt.xlabel('Number of training data')\n",
    "plt.ylabel('Average Error')\n",
    "plt.legend(loc='best')\n",
    "plt.yscale('log')\n",
    "plt.savefig('best_val_same_mse.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "for a in range(6):\n",
    "    plt.plot(ns, np.mean(mses[:, :, a, 2], axis=1), label=regressors[a])\n",
    "\n",
    "plt.title(\n",
    "    'Error on test data from a different distribution for Various models')\n",
    "plt.xlabel('Number of training data')\n",
    "plt.ylabel('Average Error')\n",
    "plt.legend(loc='best')\n",
    "plt.yscale('log')\n",
    "plt.savefig('best_val_different_mse.png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
